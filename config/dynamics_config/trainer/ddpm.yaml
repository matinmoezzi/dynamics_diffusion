defaults:
  - _self_
  - /model: MLP
  - /diffusion: gaussian
_target_: dynamics_diffusion.trainer_util.DDPMTrainer 
_recursive_: False
total_training_steps: 5e6
schedule_sampler: "uniform"
lr: 1e-4
weight_decay: 0.0
lr_anneal_steps: 0
batch_size: 16
microbatch: -1  # -1 disables microbatches
ema_rate: "0.9999"  # comma-separated list of EMA values
log_interval: 5000
save_interval: 100000
resume_checkpoint: ""
use_fp16: False
fp16_scale_growth: 1e-3
opt_name: "AdamW"

