defaults:
  - _self_
  - model/MLP
  - env/maze2d-umaze
  - diffusion/gaussian_diffusion
training_iter: -1
schedule_sampler: "uniform"
lr: 1e-4
weight_decay: 0.0
lr_anneal_steps: 0
batch_size: 1
microbatch: -1  # -1 disables microbatches
ema_rate: "0.9999"  # comma-separated list of EMA values
log_interval: 100
save_interval: 10000
resume_checkpoint: ""
use_fp16: False
fp16_scale_growth: 1e-3
hydra:
  run:
    dir: ./logs/${env.name}/${diffusion.name}/${model.name}/${now:%Y%m%d-%H%M%S}
