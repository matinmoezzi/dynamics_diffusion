{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import d4rl\n",
    "import math\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import einops\n",
    "from einops.layers.torch import Rearrange\n",
    "import pdb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Progress:\n",
    "\n",
    "\tdef __init__(self, total, name = 'Progress', ncol=3, max_length=20, indent=0, line_width=100, speed_update_freq=100):\n",
    "\t\tself.total = total\n",
    "\t\tself.name = name\n",
    "\t\tself.ncol = ncol\n",
    "\t\tself.max_length = max_length\n",
    "\t\tself.indent = indent\n",
    "\t\tself.line_width = line_width\n",
    "\t\tself._speed_update_freq = speed_update_freq\n",
    "\n",
    "\t\tself._step = 0\n",
    "\t\tself._prev_line = '\\033[F'\n",
    "\t\tself._clear_line = ' ' * self.line_width\n",
    "\n",
    "\t\tself._pbar_size = self.ncol * self.max_length\n",
    "\t\tself._complete_pbar = '#' * self._pbar_size\n",
    "\t\tself._incomplete_pbar = ' ' * self._pbar_size\n",
    "\n",
    "\t\tself.lines = ['']\n",
    "\t\tself.fraction = '{} / {}'.format(0, self.total)\n",
    "\n",
    "\t\tself.resume()\n",
    "\n",
    "\t\t\n",
    "\tdef update(self, description, n=1):\n",
    "\t\tself._step += n\n",
    "\t\tif self._step % self._speed_update_freq == 0:\n",
    "\t\t\tself._time0 = time.time()\n",
    "\t\t\tself._step0 = self._step\n",
    "\t\tself.set_description(description)\n",
    "\n",
    "\tdef resume(self):\n",
    "\t\tself._skip_lines = 1\n",
    "\t\tprint('\\n', end='')\n",
    "\t\tself._time0 = time.time()\n",
    "\t\tself._step0 = self._step\n",
    "\n",
    "\tdef pause(self):\n",
    "\t\tself._clear()\n",
    "\t\tself._skip_lines = 1\n",
    "\n",
    "\tdef set_description(self, params=[]):\n",
    "\n",
    "\t\tif type(params) == dict:\n",
    "\t\t\tparams = sorted([\n",
    "\t\t\t\t\t(key, val)\n",
    "\t\t\t\t\tfor key, val in params.items()\n",
    "\t\t\t\t])\n",
    "\n",
    "\t\t############\n",
    "\t\t# Position #\n",
    "\t\t############\n",
    "\t\tself._clear()\n",
    "\n",
    "\t\t###########\n",
    "\t\t# Percent #\n",
    "\t\t###########\n",
    "\t\tpercent, fraction = self._format_percent(self._step, self.total)\n",
    "\t\tself.fraction = fraction\n",
    "\n",
    "\t\t#########\n",
    "\t\t# Speed #\n",
    "\t\t#########\n",
    "\t\tspeed = self._format_speed(self._step)\n",
    "\n",
    "\t\t##########\n",
    "\t\t# Params #\n",
    "\t\t##########\n",
    "\t\tnum_params = len(params)\n",
    "\t\tnrow = math.ceil(num_params / self.ncol)\n",
    "\t\tparams_split = self._chunk(params, self.ncol)\n",
    "\t\tparams_string, lines = self._format(params_split)\n",
    "\t\tself.lines = lines\n",
    "\n",
    "\n",
    "\t\tdescription = '{} | {}{}'.format(percent, speed, params_string)\n",
    "\t\tprint(description)\n",
    "\t\tself._skip_lines = nrow + 1\n",
    "\n",
    "\tdef append_description(self, descr):\n",
    "\t\tself.lines.append(descr)\n",
    "\n",
    "\tdef _clear(self):\n",
    "\t\tposition = self._prev_line * self._skip_lines\n",
    "\t\tempty = '\\n'.join([self._clear_line for _ in range(self._skip_lines)])\n",
    "\t\tprint(position, end='')\n",
    "\t\tprint(empty)\n",
    "\t\tprint(position, end='')\n",
    "\t\t\n",
    "\tdef _format_percent(self, n, total):\n",
    "\t\tif total:\n",
    "\t\t\tpercent = n / float(total)\n",
    "\n",
    "\t\t\tcomplete_entries = int(percent * self._pbar_size)\n",
    "\t\t\tincomplete_entries = self._pbar_size - complete_entries\n",
    "\n",
    "\t\t\tpbar = self._complete_pbar[:complete_entries] + self._incomplete_pbar[:incomplete_entries]\n",
    "\t\t\tfraction = '{} / {}'.format(n, total)\n",
    "\t\t\tstring = '{} [{}] {:3d}%'.format(fraction, pbar, int(percent*100))\n",
    "\t\telse:\n",
    "\t\t\tfraction = '{}'.format(n)\n",
    "\t\t\tstring = '{} iterations'.format(n)\n",
    "\t\treturn string, fraction\n",
    "\n",
    "\tdef _format_speed(self, n):\n",
    "\t\tnum_steps = n - self._step0\n",
    "\t\tt = time.time() - self._time0\n",
    "\t\tspeed = num_steps / t\n",
    "\t\tstring = '{:.1f} Hz'.format(speed)\n",
    "\t\tif num_steps > 0:\n",
    "\t\t\tself._speed = string\n",
    "\t\treturn string\n",
    "\n",
    "\tdef _chunk(self, l, n):\n",
    "\t\treturn [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "\tdef _format(self, chunks):\n",
    "\t\tlines = [self._format_chunk(chunk) for chunk in chunks]\n",
    "\t\tlines.insert(0,'')\n",
    "\t\tpadding = '\\n' + ' '*self.indent\n",
    "\t\tstring = padding.join(lines)\n",
    "\t\treturn string, lines\n",
    "\n",
    "\tdef _format_chunk(self, chunk):\n",
    "\t\tline = ' | '.join([self._format_param(param) for param in chunk])\n",
    "\t\treturn line\n",
    "\n",
    "\tdef _format_param(self, param):\n",
    "\t\tk, v = param\n",
    "\t\treturn '{} : {}'.format(k, v)[:self.max_length]\n",
    "\n",
    "\tdef stamp(self):\n",
    "\t\tif self.lines != ['']:\n",
    "\t\t\tparams = ' | '.join(self.lines)\n",
    "\t\t\tstring = '[ {} ] {}{} | {}'.format(self.name, self.fraction, params, self._speed)\n",
    "\t\t\tself._clear()\n",
    "\t\t\tprint(string, end='\\n')\n",
    "\t\t\tself._skip_lines = 1\n",
    "\t\telse:\n",
    "\t\t\tself._clear()\n",
    "\t\t\tself._skip_lines = 0\n",
    "\n",
    "\tdef close(self):\n",
    "\t\tself.pause()\n",
    "\n",
    "class Silent:\n",
    "\n",
    "\tdef __init__(self, *args, **kwargs):\n",
    "\t\tpass\n",
    "\n",
    "\tdef __getattr__(self, attr):\n",
    "\t\treturn lambda *args: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "\tif torch.is_tensor(x):\n",
    "\t\tx = x.detach().cpu().numpy()\n",
    "\treturn x\n",
    "\n",
    "#-----------------------------------------------------------------------------#\n",
    "#---------------------------------- modules ----------------------------------#\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Downsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Upsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    '''\n",
    "        Conv1d --> GroupNorm --> Mish\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            Rearrange('batch channels horizon -> batch channels 1 horizon'),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            Rearrange('batch channels 1 horizon -> batch channels horizon'),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "#-----------------------------------------------------------------------------#\n",
    "#--------------------------------- attention ---------------------------------#\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1, dim, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        var = torch.var(x, dim=1, unbiased=False, keepdim=True)\n",
    "        mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv1d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
    "        q, k, v = map(lambda t: einops.rearrange(t, 'b (h c) d -> b h c d', h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        k = k.softmax(dim = -1)\n",
    "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = einops.rearrange(out, 'b h c d -> b (h c) d')\n",
    "        return self.to_out(out)\n",
    "\n",
    "#-----------------------------------------------------------------------------#\n",
    "#---------------------------------- sampling ---------------------------------#\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008, dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, steps, steps)\n",
    "    alphas_cumprod = np.cos(((x / steps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    betas_clipped = np.clip(betas, a_min=0, a_max=0.999)\n",
    "    return torch.tensor(betas_clipped, dtype=dtype)\n",
    "\n",
    "def apply_conditioning(x, conditions, action_dim):\n",
    "    for t, val in conditions.items():\n",
    "        x[:, t, action_dim:] = val.clone()\n",
    "    return x\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------#\n",
    "#---------------------------------- losses -----------------------------------#\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "class WeightedLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weights, action_dim):\n",
    "        super().__init__()\n",
    "        self.register_buffer('weights', weights)\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        '''\n",
    "            pred, targ : tensor\n",
    "                [ batch_size x horizon x transition_dim ]\n",
    "        '''\n",
    "        loss = self._loss(pred, targ)\n",
    "        weighted_loss = (loss * self.weights).mean()\n",
    "        a0_loss = (loss[:, 0, :self.action_dim] / self.weights[0, :self.action_dim]).mean()\n",
    "        return weighted_loss, {'a0_loss': a0_loss}\n",
    "\n",
    "class ValueLoss(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        loss = self._loss(pred, targ).mean()\n",
    "\n",
    "        if len(pred) > 1:\n",
    "            corr = np.corrcoef(\n",
    "                to_np(pred).squeeze(),\n",
    "                to_np(targ).squeeze()\n",
    "            )[0,1]\n",
    "        else:\n",
    "            corr = np.NaN\n",
    "\n",
    "        info = {\n",
    "            'mean_pred': pred.mean(), 'mean_targ': targ.mean(),\n",
    "            'min_pred': pred.min(), 'min_targ': targ.min(),\n",
    "            'max_pred': pred.max(), 'max_targ': targ.max(),\n",
    "            'corr': corr,\n",
    "        }\n",
    "\n",
    "        return loss, info\n",
    "\n",
    "class WeightedL1(WeightedLoss):\n",
    "\n",
    "    def _loss(self, pred, targ):\n",
    "        return torch.abs(pred - targ)\n",
    "\n",
    "class WeightedL2(WeightedLoss):\n",
    "\n",
    "    def _loss(self, pred, targ):\n",
    "        return F.mse_loss(pred, targ, reduction='none')\n",
    "\n",
    "class ValueL1(ValueLoss):\n",
    "\n",
    "    def _loss(self, pred, targ):\n",
    "        return torch.abs(pred - targ)\n",
    "\n",
    "class ValueL2(ValueLoss):\n",
    "\n",
    "    def _loss(self, pred, targ):\n",
    "        return F.mse_loss(pred, targ, reduction='none')\n",
    "\n",
    "Losses = {\n",
    "    'l1': WeightedL1,\n",
    "    'l2': WeightedL2,\n",
    "    'value_l1': ValueL1,\n",
    "    'value_l2': ValueL2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D4RLDataset(Dataset):\n",
    "\n",
    "    def __init__(self, env:gym.Env, reward_tune=None, device=\"cpu\"):\n",
    "        self.env = env\n",
    "        self.device = device\n",
    "        self.data = d4rl.qlearning_dataset(env)\n",
    "\n",
    "        self.state = torch.from_numpy(self.data['observations']).float()\n",
    "        self.action = torch.from_numpy(self.data['actions']).float()\n",
    "        self.next_state = torch.from_numpy(self.data['next_observations']).float()\n",
    "        reward = torch.from_numpy(self.data['rewards']).view(-1, 1).float()\n",
    "        self.not_done = 1. - torch.from_numpy(self.data['terminals']).view(-1, 1).float()\n",
    "\n",
    "\t    \n",
    "        self.size = self.state.shape[0]\n",
    "        self.state_dim = self.state.shape[1]\n",
    "        self.action_dim = self.action.shape[1]\n",
    "\n",
    "        self.device = device\n",
    "\t    \n",
    "        if reward_tune == 'normalize':\n",
    "            reward = (reward - reward.mean()) / reward.std()\n",
    "        elif reward_tune == 'iql_antmaze':\n",
    "            reward = reward - 1.0\n",
    "        elif reward_tune == 'iql_locomotion':\n",
    "            reward = iql_normalize(reward, self.not_done)\n",
    "        elif reward_tune == 'cql_antmaze':\n",
    "            reward = (reward - 0.5) * 4.0\n",
    "        elif reward_tune == 'antmaze':\n",
    "            reward = (reward - 0.25) * 2.0\n",
    "\t    \n",
    "        self.reward = reward\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ind = idx % self.len\n",
    "        return (\n",
    "\t\t\tself.state[ind].to(self.device),\n",
    "\t\t\tself.action[ind].to(self.device),\n",
    "\t\t\tself.next_state[ind].to(self.device),\n",
    "\t\t\tself.reward[ind].to(self.device),\n",
    "\t\t\tself.not_done[ind].to(self.device)\n",
    "\t\t)\n",
    "\n",
    "\n",
    "def iql_normalize(reward, not_done):\n",
    "\ttrajs_rt = []\n",
    "\tepisode_return = 0.0\n",
    "\tfor i in range(len(reward)):\n",
    "\t\tepisode_return += reward[i]\n",
    "\t\tif not not_done[i]:\n",
    "\t\t\ttrajs_rt.append(episode_return)\n",
    "\t\t\tepisode_return = 0.0\n",
    "\trt_max, rt_min = torch.max(torch.tensor(trajs_rt)), torch.min(torch.tensor(trajs_rt))\n",
    "\treward /= (rt_max - rt_min)\n",
    "\treward *= 1000.\n",
    "\treturn reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    MLP Model\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 x_dim,\n",
    "                 cond_dim,\n",
    "                 device=\"cpu\",\n",
    "                 t_dim=16):\n",
    "\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(t_dim),\n",
    "            nn.Linear(t_dim, t_dim * 2),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(t_dim * 2, t_dim),\n",
    "        )\n",
    "\n",
    "        input_dim = x_dim + cond_dim + t_dim\n",
    "        self.mid_layer = nn.Sequential(nn.Linear(input_dim, 256),\n",
    "                                       nn.Mish(),\n",
    "                                       nn.Linear(256, 256),\n",
    "                                       nn.Mish(),\n",
    "                                       nn.Linear(256, 256),\n",
    "                                       nn.Mish())\n",
    "\n",
    "        self.final_layer = nn.Linear(256, x_dim)\n",
    "\n",
    "    def forward(self, x, time, cond):\n",
    "\n",
    "        t = self.time_mlp(time)\n",
    "        x = torch.cat([x, t, cond], dim=1)\n",
    "        x = self.mid_layer(x)\n",
    "\n",
    "        return self.final_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualTemporalBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, embed_dim, horizon, kernel_size=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Conv1dBlock(inp_channels, out_channels, kernel_size),\n",
    "            Conv1dBlock(out_channels, out_channels, kernel_size),\n",
    "        ])\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Mish(),\n",
    "            nn.Linear(embed_dim, out_channels),\n",
    "            Rearrange('batch t -> batch t 1'),\n",
    "        )\n",
    "\n",
    "        self.residual_conv = nn.Conv1d(inp_channels, out_channels, 1) \\\n",
    "            if inp_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        '''\n",
    "            x : [ batch_size x inp_channels x horizon ]\n",
    "            t : [ batch_size x embed_dim ]\n",
    "            returns:\n",
    "            out : [ batch_size x out_channels x horizon ]\n",
    "        '''\n",
    "        out = self.blocks[0](x) + self.time_mlp(t)\n",
    "        out = self.blocks[1](out)\n",
    "        return out + self.residual_conv(x)\n",
    "\n",
    "\n",
    "class TemporalUnet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon,\n",
    "        transition_dim,\n",
    "        cond_dim,\n",
    "        dim=32,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        attention=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        print(f'[ models/temporal ] Channel dimensions: {in_out}')\n",
    "\n",
    "        time_dim = dim\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(dim),\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dim * 4, dim),\n",
    "        )\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        print(in_out)\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                ResidualTemporalBlock(dim_in, dim_out, embed_dim=time_dim, horizon=horizon),\n",
    "                ResidualTemporalBlock(dim_out, dim_out, embed_dim=time_dim, horizon=horizon),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))) if attention else nn.Identity(),\n",
    "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "            if not is_last:\n",
    "                horizon = horizon // 2\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=time_dim, horizon=horizon)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, LinearAttention(mid_dim))) if attention else nn.Identity()\n",
    "        self.mid_block2 = ResidualTemporalBlock(mid_dim, mid_dim, embed_dim=time_dim, horizon=horizon)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                ResidualTemporalBlock(dim_out * 2, dim_in, embed_dim=time_dim, horizon=horizon),\n",
    "                ResidualTemporalBlock(dim_in, dim_in, embed_dim=time_dim, horizon=horizon),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))) if attention else nn.Identity(),\n",
    "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "            if not is_last:\n",
    "                horizon = horizon * 2\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            Conv1dBlock(dim, dim, kernel_size=5),\n",
    "            nn.Conv1d(dim, transition_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cond, time):\n",
    "        '''\n",
    "            x : [ batch x horizon x transition ]\n",
    "        '''\n",
    "\n",
    "        x = einops.rearrange(x, 'b h t -> b t h')\n",
    "\n",
    "        t = self.time_mlp(time)\n",
    "        h = []\n",
    "\n",
    "        for resnet, resnet2, attn, downsample in self.downs:\n",
    "            x = resnet(x, t)\n",
    "            x = resnet2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for resnet, resnet2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, t)\n",
    "            x = resnet2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        x = einops.rearrange(x, 'b t h -> b h t')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def default_sample_fn(model, x, cond, t):\n",
    "    model_mean, _, model_log_variance = model.p_mean_variance(x=x, cond=cond, t=t)\n",
    "    model_std = torch.exp(0.5 * model_log_variance)\n",
    "\n",
    "    # no noise when t == 0\n",
    "    noise = torch.randn_like(x)\n",
    "    noise[t == 0] = 0\n",
    "\n",
    "    values = torch.zeros(len(x), device=x.device)\n",
    "    return model_mean + model_std * noise, values\n",
    "\n",
    "\n",
    "def sort_by_values(x, values):\n",
    "    inds = torch.argsort(values, descending=True)\n",
    "    x = x[inds]\n",
    "    values = values[inds]\n",
    "    return x, values\n",
    "\n",
    "\n",
    "def make_timesteps(batch_size, i, device):\n",
    "    t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "    return t\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, model, horizon, observation_dim, action_dim, n_timesteps=1000,\n",
    "        loss_type='l1', clip_denoised=False, predict_epsilon=True,\n",
    "        action_weight=1.0, loss_discount=1.0, loss_weights=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.observation_dim = observation_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.transition_dim = observation_dim + action_dim\n",
    "        self.model = model\n",
    "\n",
    "        betas = cosine_beta_schedule(n_timesteps)\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])\n",
    "\n",
    "        self.n_timesteps = int(n_timesteps)\n",
    "        self.clip_denoised = clip_denoised\n",
    "        self.predict_epsilon = predict_epsilon\n",
    "\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        self.register_buffer('posterior_variance', posterior_variance)\n",
    "\n",
    "        ## log calculation clipped because the posterior variance\n",
    "        ## is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer('posterior_log_variance_clipped',\n",
    "            torch.log(torch.clamp(posterior_variance, min=1e-20)))\n",
    "        self.register_buffer('posterior_mean_coef1',\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
    "        self.register_buffer('posterior_mean_coef2',\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))\n",
    "\n",
    "        ## get loss coefficients and initialize objective\n",
    "        loss_weights = self.get_loss_weights(action_weight, loss_discount, loss_weights)\n",
    "        self.loss_fn = Losses[loss_type](loss_weights, self.action_dim)\n",
    "\n",
    "    def get_loss_weights(self, action_weight, discount, weights_dict):\n",
    "        '''\n",
    "            sets loss coefficients for trajectory\n",
    "\n",
    "            action_weight   : float\n",
    "                coefficient on first action loss\n",
    "            discount   : float\n",
    "                multiplies t^th timestep of trajectory loss by discount**t\n",
    "            weights_dict    : dict\n",
    "                { i: c } multiplies dimension i of observation loss by c\n",
    "        '''\n",
    "        self.action_weight = action_weight\n",
    "\n",
    "        dim_weights = torch.ones(self.transition_dim, dtype=torch.float32)\n",
    "\n",
    "        ## set loss coefficients for dimensions of observation\n",
    "        if weights_dict is None: weights_dict = {}\n",
    "        for ind, w in weights_dict.items():\n",
    "            dim_weights[self.action_dim + ind] *= w\n",
    "\n",
    "        ## decay loss with trajectory timestep: discount**t\n",
    "        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)\n",
    "        discounts = discounts / discounts.mean()\n",
    "        loss_weights = torch.einsum('h,t->ht', discounts, dim_weights)\n",
    "\n",
    "        ## manually set a0 weight\n",
    "        loss_weights[0, :self.action_dim] = action_weight\n",
    "        return loss_weights\n",
    "\n",
    "    #------------------------------------------ sampling ------------------------------------------#\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        '''\n",
    "            if self.predict_epsilon, model output is (scaled) noise;\n",
    "            otherwise, model predicts x0 directly\n",
    "        '''\n",
    "        if self.predict_epsilon:\n",
    "            return (\n",
    "                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "                extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "            )\n",
    "        else:\n",
    "            return noise\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
    "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, cond, t):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=self.model(x, cond, t))\n",
    "\n",
    "        if self.clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "        else:\n",
    "            assert RuntimeError()\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
    "                x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape, cond, verbose=True, return_chain=False, sample_fn=default_sample_fn, **sample_kwargs):\n",
    "        device = self.betas.device\n",
    "\n",
    "        batch_size = shape[0]\n",
    "        x = torch.randn(shape, device=device)\n",
    "        x = apply_conditioning(x, cond, self.action_dim)\n",
    "\n",
    "        chain = [x] if return_chain else None\n",
    "\n",
    "        progress = Progress(self.n_timesteps) if verbose else Silent()\n",
    "        for i in reversed(range(0, self.n_timesteps)):\n",
    "            t = make_timesteps(batch_size, i, device)\n",
    "            x, values = sample_fn(self, x, cond, t, **sample_kwargs)\n",
    "            x = apply_conditioning(x, cond, self.action_dim)\n",
    "\n",
    "            progress.update({'t': i, 'vmin': values.min().item(), 'vmax': values.max().item()})\n",
    "            if return_chain: chain.append(x)\n",
    "\n",
    "        progress.stamp()\n",
    "\n",
    "        x, values = sort_by_values(x, values)\n",
    "        if return_chain: chain = torch.stack(chain, dim=1)\n",
    "        return Sample(x, values, chain)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def conditional_sample(self, cond, horizon=None, **sample_kwargs):\n",
    "        '''\n",
    "            conditions : [ (time, state), ... ]\n",
    "        '''\n",
    "        device = self.betas.device\n",
    "        batch_size = len(cond[0])\n",
    "        horizon = horizon or self.horizon\n",
    "        shape = (batch_size, horizon, self.transition_dim)\n",
    "\n",
    "        return self.p_sample_loop(shape, cond, **sample_kwargs)\n",
    "\n",
    "    #------------------------------------------ training ------------------------------------------#\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "\n",
    "        sample = (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def p_losses(self, x_start, cond, t):\n",
    "        noise = torch.randn_like(x_start)\n",
    "\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "        x_noisy = apply_conditioning(x_noisy, cond, self.action_dim)\n",
    "\n",
    "        x_recon = self.model(x_noisy, cond, t)\n",
    "        x_recon = apply_conditioning(x_recon, cond, self.action_dim)\n",
    "\n",
    "        assert noise.shape == x_recon.shape\n",
    "\n",
    "        if self.predict_epsilon:\n",
    "            loss, info = self.loss_fn(x_recon, noise)\n",
    "        else:\n",
    "            loss, info = self.loss_fn(x_recon, x_start)\n",
    "\n",
    "        return loss, info\n",
    "\n",
    "    def loss(self, x, *args):\n",
    "        batch_size = len(x)\n",
    "        t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()\n",
    "        return self.p_losses(x, *args, t)\n",
    "\n",
    "    def forward(self, cond, *args, **kwargs):\n",
    "        return self.conditional_sample(cond, *args, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d4rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
